#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Tue Feb 14 11:41:27 2017

@author: estelleaflalo
"""

import pandas as pd
import numpy as np
from sklearn.cross_validation import train_test_split
from sklearn.metrics import accuracy_score
import KLR_algo
import SVM_algo
import kernel_functions

#estelle
#X_tr_path='/Users/estelleaflalo/Desktop/M2_Data_Science/Second_Period/Kernel_Methods/Project/Xtr.csv'
#Y_tr_path='/Users/estelleaflalo/Desktop/M2_Data_Science/Second_Period/Kernel_Methods/Project/Ytr.csv'

#Pauline
X_tr_path = '/Users/paulinenicolas/Documents/M2_Data_Science/Kernels/Project/Xtr.csv'
Y_tr_path = '/Users/paulinenicolas/Documents/M2_Data_Science/Kernels/Project/Ytr.csv'

df_X=pd.read_csv(X_tr_path, header=None)
df_X = df_X.iloc[:, :-1]
df_y=pd.read_csv(Y_tr_path, header=None)
#df_y= df_y.iloc[:, :-1]

X=df_X.as_matrix()
y=df_y.as_matrix()[:,1]
y=y[1:]
y=y.astype(float)


#Cross validation

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,
                                                    random_state=52)
print("Nb d'échantillons d'apprentissage :  {}".format(X_train.shape[0]))
print("Nb d'échantillons de validation :    {}".format(X_test.shape[0]))



#SVM

model=SVM(0.5,kernel_test,100)
model.fit(X_train,y_train)
y_pred=model.predict(X_test)



# accuracy : pourcentage de bonnes predictions
print("Accuracy       : ", accuracy_score(y_test, y_pred))
print("Accuracy bis:  : ", np.mean(y_test == y_pred)) # mesure d'erreur 0/1

print("Le classifieur propose une bonne prédiction dans {} % des cas.".format(
      100 * accuracy_score(y_test, y_pred))) 


#KLR

<<<<<<< HEAD
for i in range(len(y_train)):
    if y_train[i]==0:
        y_train[i]=-1
    else:
        y_train[i]=1

for i in range(len(y_test)):
    if y_test[i]==0:
        y_test[i]=-1
    else:
        y_test[i]=1

n=X_train.shape[0]
alpha0=np.zeros(n)
model = KLR_algo.KLR(alpha0,1)
alpha,J_list,alpha_list = model.fit(X_train,y_train)


#prediction test
   y_pred = []

for i in range(X_test.shape[0]):
    pred = 0
    for j in  range(X_train.shape[0]):
        pred += alpha[j]*X_train[j].T.dot(X_test[i])
    y_pred.append(pred)
    print (i)
 
for i in range(len(y_pred)):
    if y_pred[i]>0:
        y_pred[i]=1
    else:
        y_pred[i]=-1
#y_pred=model.predict(X_test)
=======
n=X_train.shape[0]
alpha0=np.zeros(n)
model=KLR(alpha0,0.5,kernel_test)
model.fit(X_train,y_train)
y_pred=model.predict(X_test)
>>>>>>> 7bf7a153b9f6ad7c48e46bfa229a46240c5c2527

# accuracy : pourcentage de bonnes predictions
print("Accuracy       : ", accuracy_score(y_test, y_pred))
print("Accuracy bis:  : ", np.mean(y_test == y_pred)) # mesure d'erreur 0/1

print("Le classifieur propose une bonne prédiction dans {} % des cas.".format(
      100 * accuracy_score(y_test, y_pred))) 




